{
  "title": "Few-shot Algorithms for Consistent Neural Decoding (FALCON) Benchmark",
  "authors": [
    "Brianna M. Karpowicz",
    "Joel Ye",
    "Chaofei Fan",
    "Pablo Tostado-Marcos",
    "Fabio Rizzoglio",
    "Clay Washington",
    "Thiago Scodeler",
    "Diogo de Lucena",
    "Samuel R. Nason-Tomaszewski",
    "Matthew J. Mender",
    "Xuan Ma",
    "Ezequiel Matias Arneodo",
    "Leigh R. Hochberg",
    "Cynthia A. Chestek",
    "Jaimie M. Henderson",
    "Timothy Q. Gentner",
    "Vikash Gilja",
    "Lee E. Miller",
    "Adam G. Rouse",
    "Robert A. Gaunt",
    "Jennifer L. Collinger",
    "Chethan Pandarinath"
  ],
  "year": 2024,
  "publication": "Advances in Neural Information Processing Systems 37 (NeurIPS 2024), Datasets and Benchmarks Track",
  "abstract": "Intracortical brain-computer interfaces (iBCIs) can restore movement and communication abilities to individuals with paralysis by decoding their intended behavior from neural activity recorded with an implanted device. While this activity yields high-performance decoding over short timescales, neural data is often nonstationary, which can lead to decoder failure if not accounted for. To maintain performance, users must frequently recalibrate decoders, which requires the arduous collection of new neural and behavioral data. Aiming to reduce this burden, several approaches have been developed that either limit recalibration data requirements (few-shot approaches) or eliminate explicit recalibration entirely (zero-shot approaches). However, progress is limited by a lack of standardized datasets and comparison metrics, causing methods to be compared in an ad hoc manner. Here we introduce the FALCON benchmark suite (Few-shot Algorithms for COnsistent Neural decoding) to standardize evaluation of iBCI robustness. FALCON curates five datasets of neural and behavioral data that span movement and communication tasks to focus on behaviors of interest to modern-day iBCIs. Each dataset includes calibration data, optional few-shot recalibration data, and private evaluation data. We implement a flexible evaluation platform which only requires user-submitted code to return behavioral predictions on unseen data. We also seed the benchmark by applying baseline methods spanning several classes of possible approaches. FALCON aims to provide rigorous selection criteria for robust iBCI decoders, easing their translation to real-world devices.",
  "keywords": [
    "Intracortical BCI",
    "Neural decoding",
    "Few-shot learning",
    "Zero-shot learning",
    "Neural datasets",
    "Benchmarking",
    "BCI robustness"
  ],
  "doi": "",
  "pdf": "",
  "code": "https://snel-repo.github.io/falcon/",
  "citations": 0,
  "added_date": "",
  "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/8c2e6bb15be1894b8fb4e0f9bcad1739-Abstract-Datasets_and_Benchmarks_Track.html"
}